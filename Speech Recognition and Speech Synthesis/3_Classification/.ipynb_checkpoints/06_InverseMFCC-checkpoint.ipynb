{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6395a012-b73f-4c2a-8762-20bc8f5810e4",
   "metadata": {},
   "source": [
    "# Inversion of MFCC\n",
    "Voice control algorithms usually transform a spectrogram into MFCC and use these as input feature for a classification algorithm. If it would be possible to estimate a spectrogram out of the MFCC, it would be possible to transform a text into a spectrogram and also into a time domain signal. By this, a simple text to speech algorithm can be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26263242-7c33-4219-9389-9fe82bdd7092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 12:21:19.116293: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 12:21:19.148740: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-03 12:21:19.148765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-03 12:21:19.149598: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-03 12:21:19.154501: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-03 12:21:19.155114: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-03 12:21:20.497616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "os.chdir('../Python')\n",
    "\n",
    "import TrainingsDataInterface\n",
    "import Constants\n",
    "import RTISI\n",
    "import WaveInterface\n",
    "import TrainingsInterface\n",
    "import StreamToBlockConverter\n",
    "import BlockToSpectrogramConverter\n",
    "import AutomaticGainControl\n",
    "import MFCC\n",
    "import PsychoAcousticSpectrogram\n",
    "\n",
    "TempFolder = \"NeuralNetworks/InverseMFCC\"\n",
    "FilenameData = TempFolder + '/Data.npz'\n",
    "try:\n",
    "    os.mkdir(TempFolder)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf25c94-3ced-4b2f-9064-01842d014fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, Fs, bits = WaveInterface.ReadWave('../Audio/P501_D_EN_fm_SWB_48k.wav')\n",
    "x, Fs, bits = WaveInterface.ReadWave('../Audio/Malmsheimer48kHz.wav')\n",
    "#x, Fs, bits = ATrainingsDataInterface.GetWaveOfCommandInstance(0, 0)\n",
    "if x.shape[0] > 4*Fs: x = x[0:4*Fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c314525-f4c7-4f56-b46f-8eac2e78bcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 399)\n"
     ]
    }
   ],
   "source": [
    "def EvalMFCC(x, Fs):\n",
    "    ListOfSignalBlocks = []\n",
    "    ListOfSignalBlocks.append(StreamToBlockConverter.CStreamToBlockConverter())\n",
    "    ListOfSignalBlocks.append(BlockToSpectrogramConverter.CBlockToSpectrogramConverter())\n",
    "    ListOfSignalBlocks.append(AutomaticGainControl.CAbsoluteValues())\n",
    "    ListOfSignalBlocks.append(PsychoAcousticSpectrogram.CPsychoacousticWeighting())\n",
    "    ListOfSignalBlocks.append(MFCC.CMelFilterbank())\n",
    "    ListOfSignalBlocks.append(MFCC.CLogarithmAsSignalFlowBlock())\n",
    "    ListOfSignalBlocks.append(MFCC.CMFCC())\n",
    "    for i in range(len(ListOfSignalBlocks) - 1):\n",
    "        ListOfSignalBlocks[i].RegisterOutput(ListOfSignalBlocks[i + 1])\n",
    "    ListOfSignalBlocks[0].Initialize(Fs)\n",
    "    ListOfSignalBlocks[0].Start()\n",
    "    ListOfSignalBlocks[0].InputConnector(x)\n",
    "    return ListOfSignalBlocks[-1].GetLastOutput()\n",
    "\n",
    "Y = EvalMFCC(x, Fs)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9698058-f68b-42b1-9e37-bda9a40f0cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 399)\n"
     ]
    }
   ],
   "source": [
    "def EvalSpectrogram(x, Fs):\n",
    "    ListOfSignalBlocks = []\n",
    "    ListOfSignalBlocks.append(StreamToBlockConverter.CStreamToBlockConverter())\n",
    "    ListOfSignalBlocks.append(BlockToSpectrogramConverter.CBlockToSpectrogramConverter())\n",
    "    ListOfSignalBlocks.append(AutomaticGainControl.CAbsoluteValues())\n",
    "    ListOfSignalBlocks.append(PsychoAcousticSpectrogram.CPsychoacousticWeighting())\n",
    "    ListOfSignalBlocks.append(MFCC.CMelFilterbank())\n",
    "    for i in range(len(ListOfSignalBlocks) - 1):\n",
    "        ListOfSignalBlocks[i].RegisterOutput(ListOfSignalBlocks[i + 1])\n",
    "    ListOfSignalBlocks[0].Initialize(Fs)\n",
    "    ListOfSignalBlocks[0].Start()\n",
    "    ListOfSignalBlocks[0].InputConnector(x)\n",
    "    return ListOfSignalBlocks[-1].GetLastOutput()\n",
    "\n",
    "X = EvalSpectrogram(x, Fs)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26364ded-1089-4075-abf1-bad8c85a024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/47 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m Output\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test\n\u001b[0;32m---> 56\u001b[0m Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluateAllData\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(FilenameData, x0 \u001b[38;5;241m=\u001b[39m Input_Training, x1 \u001b[38;5;241m=\u001b[39m Output_Training, x2 \u001b[38;5;241m=\u001b[39m Input_Test, x3 \u001b[38;5;241m=\u001b[39m Output_Test, x4 \u001b[38;5;241m=\u001b[39m Input_Validation, x5 \u001b[38;5;241m=\u001b[39m Output_Validation)\n",
      "Cell \u001b[0;32mIn[6], line 24\u001b[0m, in \u001b[0;36mEvaluateAllData\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m InstanceIndex \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ATrainingsDataInterface\u001b[38;5;241m.\u001b[39mGetNumberOfCommandInstances(CommandIndex)):\n\u001b[1;32m     23\u001b[0m     x, Fs, bits \u001b[38;5;241m=\u001b[39m ATrainingsDataInterface\u001b[38;5;241m.\u001b[39mGetWaveOfCommandInstance(CommandIndex, InstanceIndex)\n\u001b[0;32m---> 24\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mEvalSpectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     Y \u001b[38;5;241m=\u001b[39m EvalMFCC(x, Fs)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mamin(X) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspectrogram should be greater or equal zero\u001b[39m\u001b[38;5;124m'\u001b[39m   \n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mEvalSpectrogram\u001b[0;34m(x, Fs)\u001b[0m\n\u001b[1;32m     10\u001b[0m ListOfSignalBlocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mInitialize(Fs)\n\u001b[1;32m     11\u001b[0m ListOfSignalBlocks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mStart()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mListOfSignalBlocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInputConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ListOfSignalBlocks[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mGetLastOutput()\n",
      "File \u001b[0;32m~/Python/VoiceControl/Python/SignalFlowBlock.py:61\u001b[0m, in \u001b[0;36mCSignalFlowBlock.InputConnector\u001b[0;34m(self, NewInput)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__OutputsActive:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m OutputConnector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ListOfOutputBlocks:\n\u001b[0;32m---> 61\u001b[0m         \u001b[43mOutputConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInputConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__LastOutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__LastOutput\n",
      "File \u001b[0;32m~/Python/VoiceControl/Python/SignalFlowBlock.py:61\u001b[0m, in \u001b[0;36mCSignalFlowBlock.InputConnector\u001b[0;34m(self, NewInput)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__OutputsActive:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m OutputConnector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ListOfOutputBlocks:\n\u001b[0;32m---> 61\u001b[0m         \u001b[43mOutputConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInputConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__LastOutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__LastOutput\n",
      "    \u001b[0;31m[... skipping similar frames: CSignalFlowBlock.InputConnector at line 61 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/Python/VoiceControl/Python/SignalFlowBlock.py:61\u001b[0m, in \u001b[0;36mCSignalFlowBlock.InputConnector\u001b[0;34m(self, NewInput)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__OutputsActive:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m OutputConnector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ListOfOutputBlocks:\n\u001b[0;32m---> 61\u001b[0m         \u001b[43mOutputConnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInputConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__LastOutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__LastOutput\n",
      "File \u001b[0;32m~/Python/VoiceControl/Python/SignalFlowBlock.py:58\u001b[0m, in \u001b[0;36mCSignalFlowBlock.InputConnector\u001b[0;34m(self, NewInput)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mInputConnector\u001b[39m(\u001b[38;5;28mself\u001b[39m, NewInput):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__StartDone, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCall Start() before InputConnector()\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__LastOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__TransferFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNewInput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__OutputsActive:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m OutputConnector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ListOfOutputBlocks:\n",
      "File \u001b[0;32m~/Python/VoiceControl/Python/MFCC.py:142\u001b[0m, in \u001b[0;36mCMelFilterbank.__TransferFunction\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__T_Hertz2Bark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__Initialize(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__T_Hertz2Bark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TimeMemoryOfInput = 3\n",
    "IsTestMode = False\n",
    "\n",
    "def GetAudioWithConstantLength(x, Fs):\n",
    "    AudioDataLengthInMilliseconds = 500\n",
    "    LengthInSamples = int(AudioDataLengthInMilliseconds * Fs / 1000)\n",
    "    if x.shape[0] < LengthInSamples:\n",
    "        y = np.concatenate((x, np.zeros((LengthInSamples - x.shape[0]))), axis = 0)\n",
    "    else:\n",
    "        E_cumsum = np.cumsum(x**2)\n",
    "        tmp = E_cumsum[LengthInSamples:]\n",
    "        tmp -= E_cumsum[:tmp.shape[0]]\n",
    "        MaxIndex = np.argmax(tmp)\n",
    "        y = x[MaxIndex:MaxIndex + LengthInSamples]\n",
    "    assert np.abs(y.shape[0] - LengthInSamples) < 1e-1, 'wrong output length'\n",
    "    return y\n",
    "\n",
    "def EvaluateAllData():\n",
    "    TrainingsCounter = 0\n",
    "    Input = None\n",
    "    ATrainingsDataInterface = TrainingsDataInterface.CTrainingsDataInterface()\n",
    "    for CommandIndex in tqdm(range(15)):#range(ATrainingsDataInterface.GetNumberOfCommands()):\n",
    "        MaxInstanceIndex = ATrainingsDataInterface.GetNumberOfCommandInstances(CommandIndex)\n",
    "        if IsTestMode and (MaxInstanceIndex > 10): MaxInstanceIndex = 10\n",
    "        for InstanceIndex in range(MaxInstanceIndex):\n",
    "            x, Fs, bits = ATrainingsDataInterface.GetWaveOfCommandInstance(CommandIndex, InstanceIndex)\n",
    "            X = EvalSpectrogram(x, Fs)\n",
    "            Y = EvalMFCC(x, Fs)\n",
    "            assert np.amin(X) >= 0.0, 'spectrogram should be greater or equal zero'   \n",
    "            if Input is None:\n",
    "                Input = np.zeros((250000, Y.shape[0], TimeMemoryOfInput))\n",
    "                Output = np.zeros((Input.shape[0], X.shape[0]))\n",
    "            idx1 = 0\n",
    "            idx2 = Input.shape[2]\n",
    "            while idx2 < Y.shape[1]:\n",
    "                Input[TrainingsCounter, :, :] = Y[:, idx1:idx2]\n",
    "                Output[TrainingsCounter, :] = X[:, idx2]\n",
    "                idx1 += 1\n",
    "                idx2 += 1\n",
    "                TrainingsCounter += 1\n",
    "    \n",
    "    # partitioning in training, validation, test\n",
    "    PercentageTraining = 0.8\n",
    "    PercentageValidation = 0.1\n",
    "    PercentageTest = 1.0 - PercentageTraining - PercentageValidation\n",
    "    assert PercentageTest > 0.0, 'wrong partitioning between training, validation and test'\n",
    "    LastIndexTraining = int(TrainingsCounter * PercentageTraining)\n",
    "    LastIndexValidation = int(TrainingsCounter * (PercentageTraining + PercentageValidation))\n",
    "    Input_Training = Input[:LastIndexTraining, ...]\n",
    "    Output_Training = Output[:LastIndexTraining, ...]\n",
    "    Input_Validation = Input[LastIndexTraining:LastIndexValidation, ...]\n",
    "    Output_Validation = Output[LastIndexTraining:LastIndexValidation, ...]\n",
    "    Input_Test = Input[LastIndexValidation:TrainingsCounter, ...]\n",
    "    Output_Test = Output[LastIndexValidation:TrainingsCounter, ...]\n",
    "    del Input\n",
    "    del Output\n",
    "    return Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test\n",
    "\n",
    "Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test = EvaluateAllData()\n",
    "np.savez(FilenameData, x0 = Input_Training, x1 = Output_Training, x2 = Input_Test, x3 = Output_Test, x4 = Input_Validation, x5 = Output_Validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a355aaa8-96a5-4d88-bde3-22804fd02579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllData():    \n",
    "    try:\n",
    "        data = np.load(FilenameData)\n",
    "        Input_Training = data['x0']\n",
    "        Output_Training = data['x1']\n",
    "        Input_Test = data['x2']\n",
    "        Output_Test = data['x3']\n",
    "        Input_Validation = data['x4']\n",
    "        Output_Validation = data['x5']\n",
    "    except:\n",
    "        Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test = EvaluateAllData()\n",
    "        np.savez(FilenameData, x0 = Input_Training, x1 = Output_Training, x2 = Input_Test, x3 = Output_Test, x4 = Input_Validation, x5 = Output_Validation)\n",
    "    return Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test\n",
    "\n",
    "Input_Training, Output_Training, Input_Validation, Output_Validation, Input_Test, Output_Test = GetAllData()\n",
    "print('number of trainings samples: ', Input_Training.shape[0])\n",
    "print('number of validation samples: ', Input_Validation.shape[0])\n",
    "print('number of test samples: ', Input_Test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e92dbb-e6dc-4c1a-ba98-2f36837d3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 10:42:21.446436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-03 10:42:21.537270: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(Input_Training.shape[1], Input_Training.shape[2])),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(500, activation='LeakyReLU'),\n",
    "    tf.keras.layers.Dense(200, activation='LeakyReLU'),\n",
    "    tf.keras.layers.Dense(50, activation='LeakyReLU'),\n",
    "    tf.keras.layers.Dense(Output_Training.shape[1], activation='ReLU')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96be3442-0ab3-48e3-9e0c-8a06c9efb69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = TempFolder + \"/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cbCheckpoints = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "cbEarlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "try:\n",
    "    model.load_weights(checkpoint_path)\n",
    "except:\n",
    "    print('problem loading old weights, starting with scratch new network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5790cde4-fc58-4a41-9adb-4717a18565d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 10:42:35.252588: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2087000280 exceeds 10% of free system memory.\n",
      "2023-12-03 10:43:35.130972: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 417400056 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "85806/85815 [============================>.] - ETA: 0s - loss: 1.4957e-07"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-03 10:47:20.205558: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 260875320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 225s 2ms/step - loss: 1.4956e-07 - val_loss: 4.4056e-09\n",
      "Epoch 2/1000\n",
      "85802/85815 [============================>.] - ETA: 0s - loss: 5.5563e-09\n",
      "Epoch 2: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 207s 2ms/step - loss: 5.5566e-09 - val_loss: 7.4476e-09\n",
      "Epoch 3/1000\n",
      "85815/85815 [==============================] - ETA: 0s - loss: 4.9957e-09\n",
      "Epoch 3: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 207s 2ms/step - loss: 4.9957e-09 - val_loss: 3.0943e-09\n",
      "Epoch 4/1000\n",
      "85814/85815 [============================>.] - ETA: 0s - loss: 4.6910e-09\n",
      "Epoch 4: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 208s 2ms/step - loss: 4.6910e-09 - val_loss: 4.7554e-09\n",
      "Epoch 5/1000\n",
      "85804/85815 [============================>.] - ETA: 0s - loss: 4.5042e-09\n",
      "Epoch 5: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 207s 2ms/step - loss: 4.5039e-09 - val_loss: 3.3814e-09\n",
      "Epoch 6/1000\n",
      "85811/85815 [============================>.] - ETA: 0s - loss: 4.3325e-09\n",
      "Epoch 6: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 208s 2ms/step - loss: 4.3326e-09 - val_loss: 5.1529e-09\n",
      "Epoch 7/1000\n",
      "85797/85815 [============================>.] - ETA: 0s - loss: 4.2026e-09\n",
      "Epoch 7: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 207s 2ms/step - loss: 4.2021e-09 - val_loss: 2.4973e-08\n",
      "Epoch 8/1000\n",
      "85799/85815 [============================>.] - ETA: 0s - loss: 4.0821e-09\n",
      "Epoch 8: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 209s 2ms/step - loss: 4.0818e-09 - val_loss: 2.8008e-09\n",
      "Epoch 9/1000\n",
      "85798/85815 [============================>.] - ETA: 0s - loss: 4.0061e-09\n",
      "Epoch 9: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 217s 3ms/step - loss: 4.0056e-09 - val_loss: 2.2546e-09\n",
      "Epoch 10/1000\n",
      "85814/85815 [============================>.] - ETA: 0s - loss: 3.9413e-09\n",
      "Epoch 10: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 212s 2ms/step - loss: 3.9413e-09 - val_loss: 3.5951e-09\n",
      "Epoch 11/1000\n",
      "85803/85815 [============================>.] - ETA: 0s - loss: 3.8670e-09\n",
      "Epoch 11: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 214s 2ms/step - loss: 3.8668e-09 - val_loss: 2.9196e-09\n",
      "Epoch 12/1000\n",
      "85805/85815 [============================>.] - ETA: 0s - loss: 3.8154e-09\n",
      "Epoch 12: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 214s 2ms/step - loss: 3.8153e-09 - val_loss: 3.1071e-09\n",
      "Epoch 13/1000\n",
      "85813/85815 [============================>.] - ETA: 0s - loss: 3.7570e-09\n",
      "Epoch 13: saving model to NeuralNetworks/InverseMFCC/cp.ckpt\n",
      "85815/85815 [==============================] - 212s 2ms/step - loss: 3.7570e-09 - val_loss: 2.3489e-09\n",
      "Epoch 14/1000\n",
      "  934/85815 [..............................] - ETA: 3:29 - loss: 3.6717e-09"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Input_Training, Output_Training, epochs=1000,\n",
    "                    validation_data=(Input_Validation, Output_Validation),\n",
    "                    callbacks=[cbEarlyStopping, cbCheckpoints], verbose = 1)\n",
    "print('training finished after ', len(history.history['loss']), ' epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55cb3387-7cfd-4c36-97e2-a7a6f240daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step\n",
      "mean SNR of prediction =  -39.19553932084021  dB\n"
     ]
    }
   ],
   "source": [
    "SNR = 0.0\n",
    "y = model.predict(Input_Test)\n",
    "for SampleIndex in range(Input_Test.shape[0]):\n",
    "    x = Output_Test[SampleIndex, :]\n",
    "    SNR += 10*np.log10(np.sum(x**2) / np.sum((x-y[SampleIndex, :])**2))\n",
    "SNR /= Input_Test.shape[0]\n",
    "print('mean SNR of prediction = ', SNR, ' dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401dd3c0-c529-4b1c-8d96-76ec2d799c5c",
   "metadata": {},
   "source": [
    "## Programming exercise\n",
    "\n",
    "Try different model architectures in order to increase the accuracy of the model:\n",
    "\n",
    "1) Try to increase the number of layers by inserting new layers:\n",
    "   \n",
    "   tf.keras.layers.Dense(units = NumberOfNeurons, activation='LeakyReLU').\n",
    "\n",
    "2) Try to increase the number of neurons per layer by increasing the parameter units:\n",
    "\n",
    "   tf.keras.layers.Dense(units = NumberOfNeurons, activation='LeakyReLU').\n",
    "\n",
    "3) Try to insert regularization layers, e.g.\n",
    "\n",
    "   tf.keras.layers.Dropout(.2),\n",
    "\n",
    "   tf.keras.layers.BatchNormalization() or others.\n",
    "\n",
    "4) Try to modify the dense layers with weight regularizers, as shown in the following:\n",
    "\n",
    "    tf.keras.layers.Dense(\n",
    "    units=NumberOfNeurons,\n",
    "    kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=regularizers.L2(1e-4),\n",
    "    activity_regularizer=regularizers.L2(1e-5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8200d-dd43-48d3-b95d-d414456283e7",
   "metadata": {},
   "source": [
    "## Exam preparation\n",
    "\n",
    "1) Can you invert a linear operation $y_j=T\\cdot x_i=sum_{i=0}^{I-1}T(j,i)\\cdot x_i$ for $0\\leq j<J$? Yes, if $I=J$ and if the matrix $T$ is invertible. Otherwise, only the pseudo inverse can be used for inverting the linear operation.\n",
    "\n",
    "2) Is the evaluation of the MFCC a linear operation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
