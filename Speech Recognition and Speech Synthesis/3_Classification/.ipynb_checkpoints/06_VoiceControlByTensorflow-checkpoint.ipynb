{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd18fc0-945c-4102-bdc1-65ad9d20cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installed version of Tensorflow:  2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "os.chdir('../Python')\n",
    "import TrainingsDataInterface\n",
    "import TrainingsInterface\n",
    "import Train\n",
    "import DatasetAugmentation\n",
    "import Constants\n",
    "\n",
    "print('installed version of Tensorflow: ', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5555b730-7e12-455d-8fb1-00f6c4ea3d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c0aca6-7e0c-4e5c-9161-dd7e5bc5fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [01:21<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1565, 38, 69)\n",
      "(1565,)\n"
     ]
    }
   ],
   "source": [
    "AudioDataLengthInMilliseconds = Constants.theConstants.getWordLengthInMilliseconds()\n",
    "NumberOfTestSamples = 20\n",
    "NumberOfValidationSamples = 20\n",
    "\n",
    "ATrainingsDataInterface = TrainingsDataInterface.CTrainingsDataInterface()\n",
    "def GetNumberOfTrainingsData():\n",
    "    res = 0\n",
    "    for CommandIndex in range(ATrainingsDataInterface.GetNumberOfCommands()):\n",
    "        command = ATrainingsDataInterface.GetCommandString(CommandIndex)\n",
    "        if command in Train.VOCABULARY:\n",
    "            NewSamples = ATrainingsDataInterface.GetNumberOfCommandInstances(CommandIndex)\n",
    "            NewSamples -= NumberOfTestSamples\n",
    "            NewSamples -= NumberOfValidationSamples\n",
    "            assert NewSamples > 0, str('not enough training samples for command ' + command)\n",
    "            res += NewSamples\n",
    "    return res\n",
    "\n",
    "def GetAudioWithConstantLength(x, Fs):\n",
    "    LengthInSamples = int(AudioDataLengthInMilliseconds * Fs / 1000)\n",
    "    if x.shape[0] < LengthInSamples:\n",
    "        y = np.concatenate((x, np.zeros((LengthInSamples - x.shape[0]))), axis = 0)\n",
    "    else:\n",
    "        E_cumsum = np.cumsum(x**2)\n",
    "        tmp = E_cumsum[LengthInSamples:]\n",
    "        tmp -= E_cumsum[:tmp.shape[0]]\n",
    "        MaxIndex = np.argmax(tmp)\n",
    "        y = x[MaxIndex:MaxIndex + LengthInSamples]\n",
    "    assert np.abs(y.shape[0] - LengthInSamples) < 1e-1, 'wrong output length'\n",
    "    return y\n",
    "\n",
    "def IsTraining(InstanceIndex):\n",
    "    return not (IsTest(InstanceIndex) or IsValidation(InstanceIndex))\n",
    "\n",
    "def IsValidation(InstanceIndex):\n",
    "    return (not IsTest(InstanceIndex)) and (InstanceIndex < (NumberOfTestSamples + NumberOfValidationSamples))\n",
    "\n",
    "def IsTest(InstanceIndex):\n",
    "    return InstanceIndex < NumberOfTestSamples\n",
    "\n",
    "def EvaluateAllData():\n",
    "    Constants.theConstants.SetUseVAD(False)\n",
    "    train_images = None\n",
    "    train_counter = 0\n",
    "    test_counter = 0\n",
    "    validation_counter = 0\n",
    "    for CommandIndex in tqdm(range(ATrainingsDataInterface.GetNumberOfCommands())):\n",
    "        command = ATrainingsDataInterface.GetCommandString(CommandIndex)\n",
    "        if command in Train.VOCABULARY:\n",
    "            for n in range(len(Train.VOCABULARY)):\n",
    "                if Train.VOCABULARY[n] == command:\n",
    "                    commandlabel = n\n",
    "            for InstanceIndex in range(ATrainingsDataInterface.GetNumberOfCommandInstances(CommandIndex)):\n",
    "                x, Fs, bits = ATrainingsDataInterface.GetWaveOfCommandInstance(CommandIndex, InstanceIndex)\n",
    "                assert np.abs(Constants.theConstants.getSamplingFrequencyMicrofone() - Fs) < 1e-3, 'wrong sampling rate'\n",
    "                ADatasetAugmentation = DatasetAugmentation.CAudioDatasetAugmentation(x, Fs)\n",
    "                NumberOfDistortions = 1#ADatasetAugmentation.GetNumberOfResults()\n",
    "                if IsTraining(InstanceIndex):\n",
    "                    MaxDistortionIndex = NumberOfDistortions\n",
    "                else:\n",
    "                    MaxDistortionIndex = 1\n",
    "                for DistortionIndex in range(MaxDistortionIndex):\n",
    "                    y, Timestretchfactor = ADatasetAugmentation.GenerateSingleDistortion(DistortionIndex)\n",
    "                    z = GetAudioWithConstantLength(y, Fs)\n",
    "                    Feature = TrainingsInterface.SamplesToFeature(z, Fs)\n",
    "                    if train_images is None:\n",
    "                        train_images = np.zeros((GetNumberOfTrainingsData()*NumberOfDistortions, Feature.shape[0], Feature.shape[1]))\n",
    "                        test_images = np.zeros((NumberOfTestSamples*len(Train.VOCABULARY), Feature.shape[0], Feature.shape[1]))\n",
    "                        validation_images = np.zeros((NumberOfValidationSamples*len(Train.VOCABULARY), Feature.shape[0], Feature.shape[1]))\n",
    "                        train_labels = np.zeros((train_images.shape[0]))\n",
    "                        test_labels = np.zeros((test_images.shape[0]))\n",
    "                        validation_labels = np.zeros((validation_images.shape[0]))\n",
    "                    if IsTraining(InstanceIndex):\n",
    "                        train_images[train_counter, :, :] = Feature\n",
    "                        train_labels[train_counter] = commandlabel\n",
    "                        train_counter += 1   \n",
    "                    elif IsTest(InstanceIndex):\n",
    "                        test_images[test_counter, :, :] = Feature\n",
    "                        test_labels[test_counter] = commandlabel\n",
    "                        test_counter += 1   \n",
    "                    else:\n",
    "                        validation_images[validation_counter, :, :] = Feature\n",
    "                        validation_labels[validation_counter] = commandlabel\n",
    "                        validation_counter += 1                         \n",
    "    return train_images, train_labels, test_images, test_labels, validation_images, validation_labels\n",
    "\n",
    "def GetAllData():\n",
    "    Filename = 'tmp.npz'\n",
    "    try:\n",
    "        x = 1/0\n",
    "        data = np.load(Filename)\n",
    "        train_images = data['x0']\n",
    "        train_labels = data['x1']\n",
    "        test_images = data['x2']\n",
    "        test_labels = data['x3']\n",
    "        validation_images = data['x4']\n",
    "        validation_labels = data['x5']\n",
    "    except:\n",
    "        train_images, train_labels, test_images, test_labels, validation_images, validation_labels = EvaluateAllData()\n",
    "        np.savez(Filename, x0 = train_images, x1 = train_labels, x2 = test_images, x3 = test_labels, x4 = validation_images, x5 = validation_labels)\n",
    "    return train_images, train_labels, test_images, test_labels, validation_images, validation_labels\n",
    "\n",
    "train_images, train_labels, test_images, test_labels, validation_images, validation_labels = GetAllData()\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b360eb-0b4b-4fbc-9211-7ad8cdaa45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(train_images.shape[1], train_images.shape[2])),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(Train.VOCABULARY))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c1c64-14da-4de4-926a-4618127926e7",
   "metadata": {},
   "source": [
    "For classification tasks, the cross entropy is typically chosen as loss function for training. The cross entropy is defined by:\n",
    "\n",
    "$L=-\\sum_j o_j\\cdot\\log z_j$\n",
    "\n",
    "with $o_j$ corresponding to the correct output and $z_j$ corresponding to the current output of the neural network during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ebdcb6-ca51-497c-882b-9e91907242bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished after  8  epochs\n",
      "6/6 - 0s - loss: 0.9335 - accuracy: 0.6556 - 40ms/epoch - 7ms/step\n",
      "\n",
      "Test accuracy: 0.6555555462837219\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=1000, validation_data=(validation_images, validation_labels), callbacks=[callback], verbose = 0)\n",
    "print('training finished after ', len(history.history['loss']), ' epochs')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68236fa-fc8f-46cb-bd22-445737ca487e",
   "metadata": {},
   "source": [
    "Trainingsbeispiele für Tensorflow:\n",
    "1 notebook: Klassifikation der Wörter mit Datasetaugmentation, regularisierung, ...\n",
    "1 notebook: funktion transformiert Spektrogramm in MFCC, DMFCC und DDMFCC, kann Tensorflow diese Funktion invertieren?\n",
    "1 notebook: Tiefpass ohne Latenz mit Tensorflow basteln?\n",
    "1 notebook: Nachbildung der webrtcvad?\n",
    "\n",
    "Exam Preparation:\n",
    "Was war die Problemstellung?\n",
    "Warum benötigt man ein nicht-lineares System?\n",
    "Was für Probleme traten generell auf?\n",
    "War es schwierig die Trainingsdaten zu erzeugen?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
